{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1becfaa",
   "metadata": {
    "id": "e1becfaa"
   },
   "source": [
    "### Author:: \\<Fatemeh Vahabi\\>\n",
    "ID::     \\<4013614052\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e53b13d3",
   "metadata": {
    "id": "e53b13d3"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.classify.scikitlearn import SklearnClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bb20a9-af47-457a-9dcd-2a00862faeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### در قطعه کد بالا کتابخانه های لازم را فراخوانی کردم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "z2319ngZ0OGG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z2319ngZ0OGG",
    "outputId": "b08e544e-d57c-4669-bd39-2a0ab69eba8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.7)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.6.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "!pip install nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6R-WOg4l0OM7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6R-WOg4l0OM7",
    "outputId": "2ee16956-c617-47f9-8852-eb2cc7d70f10"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2711cdd-e6ee-47d8-a1c3-17b05536df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### در بخش زیر دیتاست را بارگذاری میکنیم."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b25b1d",
   "metadata": {
    "id": "b0b25b1d"
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698ae57c-595e-4992-b924-8748a1d7128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### در بخش زیر همانطور که نوشته شده است، جاهایی از جدول که خالی نیستند را نگه می داریم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "250c1f16",
   "metadata": {
    "id": "250c1f16"
   },
   "outputs": [],
   "source": [
    "youtube = pd.read_table('/content/youtube.csv', encoding='utf-8', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed50e9ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "ed50e9ba",
    "outputId": "ee74b892-484f-4d71-b640-da3b4110a738"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9ff1f64b-ec72-4eb4-8dfa-ed8b2af24cc6\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU</td>\n",
       "      <td>Julius NM</td>\n",
       "      <td>2013-11-07T06:20:48</td>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A</td>\n",
       "      <td>adam riyati</td>\n",
       "      <td>2013-11-07T12:37:15</td>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8</td>\n",
       "      <td>Evgeny Murashkin</td>\n",
       "      <td>2013-11-08T17:34:21</td>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13jhp0bxqncu512g22wvzkasxmvvzjaz04</td>\n",
       "      <td>ElNino Melendez</td>\n",
       "      <td>2013-11-09T08:28:43</td>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13fwbwp1oujthgqj04chlngpvzmtt3r3dw</td>\n",
       "      <td>GsMega</td>\n",
       "      <td>2013-11-10T16:05:38</td>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>z13th1q4yzihf1bll23qxzpjeujterydj</td>\n",
       "      <td>Carmen Racasanu</td>\n",
       "      <td>2014-11-14T13:27:52</td>\n",
       "      <td>How can this have 2 billion views when there's...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>z13fcn1wfpb5e51xe04chdxakpzgchyaxzo0k</td>\n",
       "      <td>diego mogrovejo</td>\n",
       "      <td>2014-11-14T13:28:08</td>\n",
       "      <td>I don't now why I'm watching this in 2014﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>z130zd5b3titudkoe04ccbeohojxuzppvbg</td>\n",
       "      <td>BlueYetiPlayz -Call Of Duty and More</td>\n",
       "      <td>2015-05-23T13:04:32</td>\n",
       "      <td>subscribe to me for call of duty vids and give...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>z12he50arvrkivl5u04cctawgxzkjfsjcc4</td>\n",
       "      <td>Photo Editor</td>\n",
       "      <td>2015-06-05T14:14:48</td>\n",
       "      <td>hi guys please my android photo editor downloa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>z13vhvu54u3ewpp5h04ccb4zuoardrmjlyk0k</td>\n",
       "      <td>Ray Benich</td>\n",
       "      <td>2015-06-05T18:05:16</td>\n",
       "      <td>The first billion viewed this because they tho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 5 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ff1f64b-ec72-4eb4-8dfa-ed8b2af24cc6')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-9ff1f64b-ec72-4eb4-8dfa-ed8b2af24cc6 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-9ff1f64b-ec72-4eb4-8dfa-ed8b2af24cc6');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                      COMMENT_ID  \\\n",
       "0    LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU   \n",
       "1    LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A   \n",
       "2    LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8   \n",
       "3            z13jhp0bxqncu512g22wvzkasxmvvzjaz04   \n",
       "4            z13fwbwp1oujthgqj04chlngpvzmtt3r3dw   \n",
       "..                                           ...   \n",
       "345            z13th1q4yzihf1bll23qxzpjeujterydj   \n",
       "346        z13fcn1wfpb5e51xe04chdxakpzgchyaxzo0k   \n",
       "347          z130zd5b3titudkoe04ccbeohojxuzppvbg   \n",
       "348          z12he50arvrkivl5u04cctawgxzkjfsjcc4   \n",
       "349        z13vhvu54u3ewpp5h04ccb4zuoardrmjlyk0k   \n",
       "\n",
       "                                   AUTHOR                 DATE  \\\n",
       "0                               Julius NM  2013-11-07T06:20:48   \n",
       "1                             adam riyati  2013-11-07T12:37:15   \n",
       "2                        Evgeny Murashkin  2013-11-08T17:34:21   \n",
       "3                         ElNino Melendez  2013-11-09T08:28:43   \n",
       "4                                  GsMega  2013-11-10T16:05:38   \n",
       "..                                    ...                  ...   \n",
       "345                       Carmen Racasanu  2014-11-14T13:27:52   \n",
       "346                       diego mogrovejo  2014-11-14T13:28:08   \n",
       "347  BlueYetiPlayz -Call Of Duty and More  2015-05-23T13:04:32   \n",
       "348                          Photo Editor  2015-06-05T14:14:48   \n",
       "349                            Ray Benich  2015-06-05T18:05:16   \n",
       "\n",
       "                                               CONTENT  CLASS  \n",
       "0    Huh, anyway check out this you[tube] channel: ...      1  \n",
       "1    Hey guys check out my new channel and our firs...      1  \n",
       "2               just for test I have to say murdev.com      1  \n",
       "3     me shaking my sexy ass on my channel enjoy ^_^ ﻿      1  \n",
       "4              watch?v=vtaRGgvGtWQ   Check this out .﻿      1  \n",
       "..                                                 ...    ...  \n",
       "345  How can this have 2 billion views when there's...      0  \n",
       "346         I don't now why I'm watching this in 2014﻿      0  \n",
       "347  subscribe to me for call of duty vids and give...      1  \n",
       "348  hi guys please my android photo editor downloa...      1  \n",
       "349  The first billion viewed this because they tho...      0  \n",
       "\n",
       "[350 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In case of Nan values for the 'CONTENT' column\n",
    "youtube = youtube[youtube['CONTENT'].notna()]\n",
    "\n",
    "youtube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af9d4d2",
   "metadata": {
    "id": "4af9d4d2"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfd778a-e5e3-46a0-8fd0-2d0d12456b24",
   "metadata": {
    "id": "fb64b1e2-768f-4be1-8376-f3ba2d316a01"
   },
   "source": [
    "#### در قطعه کد زیر استاپ‌ورد ها را از بین بردم که در نتیجه نهایی تاثیر خوبی نداشت و زمانی که این بخش را از مرجله پیش پردازش حذف کردم، نتیجه بهتری به دست آمد.لذا این بخش را فقط برای نمایش به صورت کامنت قرار دادم."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca5885d-2cc8-4b4b-bc3e-a8eaa4dfadab",
   "metadata": {
    "id": "1ca5885d-2cc8-4b4b-bc3e-a8eaa4dfadab"
   },
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "for i in range (len(youtube['CONTENT'])):\n",
    "    #print(youtube['CONTENT'][i])\n",
    "    #stop_words = set(stopwords.words(‘english’))\n",
    "    #tokens = word_tokenize(comment)\n",
    "    #result = [i for i in tokens if not i in stop_words]\n",
    "    stop_words = stopwords.words('english')\n",
    "    #tokens = word_tokenize(comment)\n",
    "    words = word_tokenize(youtube['CONTENT'][i])\n",
    "    youtube['CONTENT'][i] = [i for i in words if not i in stop_words]\n",
    "    c=''\n",
    "    for j in youtube['CONTENT'][i]:\n",
    "        c+=j\n",
    "        c+=' '\n",
    "    #print(c)\n",
    "    youtube['CONTENT'][i]=c\n",
    "    #print(youtube['CONTENT'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79be133-252f-4e84-8434-e716f02388cd",
   "metadata": {
    "id": "d79be133-252f-4e84-8434-e716f02388cd"
   },
   "source": [
    "import string\n",
    "for i in range (len(youtube['CONTENT'])):\n",
    "    result = youtube['CONTENT'][i].translate(string.maketrans('',''), string.punctuation)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305e62bb-5669-43ea-ab61-c5733f0fa9e3",
   "metadata": {
    "id": "305e62bb-5669-43ea-ab61-c5733f0fa9e3"
   },
   "source": [
    "import re\n",
    "for i in range (len(youtube['CONTENT'])):\n",
    "    youtube['CONTENT'][i] = re.sub(r'\\d+', '', youtube['CONTENT'][i])\n",
    "    #print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e397f0a9-87f3-461d-bdd3-dc2b2a20cd40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e397f0a9-87f3-461d-bdd3-dc2b2a20cd40",
    "outputId": "5641b5d7-edbf-47ab-84d2-b01af0520a0d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "TBulNZ4r0nAb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBulNZ4r0nAb",
    "outputId": "752e6efe-1bf7-4b90-e370-1b4689a71d77"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "162831e0-bddd-4165-b3fc-e910ed2ad2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your preprocessing code goes here\n",
    "#(Note: get the contents of the youtube['CONTENT'] column and replace them with your preprocessed results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88847842-292d-48da-8e01-a8371e1f0ec7",
   "metadata": {},
   "source": [
    "## delete punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d54cc21-d01f-4cfa-ba5b-2e5610ce6b80",
   "metadata": {},
   "source": [
    "#### تابع زیر برای تبدیل یک رشته به صورت حرف به حرف است. در واقع علائم نگارشی به صورت یک رشته به هم چسبیده بود که تابع زیر ان ها را جدا میکند و به صورت یک لیست بازمیگرداند که بدین ترتیب می توان از ان لیست استفاده کرد تا علائم نگارشی را حذف کنیم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "34bb882d-df35-4449-96dc-0f0b54368e13",
   "metadata": {
    "id": "34bb882d-df35-4449-96dc-0f0b54368e13"
   },
   "outputs": [],
   "source": [
    "def Convert(string):\n",
    "    list1 = []\n",
    "    list1[:0] = string\n",
    "    return list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9b9057fd-da84-4578-b4cd-7b83c38de10a",
   "metadata": {
    "id": "9b9057fd-da84-4578-b4cd-7b83c38de10a"
   },
   "outputs": [],
   "source": [
    "import string   \n",
    "# Storing the sets of punctuation in variable result \n",
    "result = string.punctuation  \n",
    "# Printing the punctuation values \n",
    "result=Convert(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "363bbc92-a034-44c3-9fc6-d55a6db0e0f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "363bbc92-a034-44c3-9fc6-d55a6db0e0f0",
    "outputId": "9845bf38-0001-4f92-d255-ddeb65f7cd98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-64-0c63c07eb46a>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  youtube['CONTENT'][i]=youtube['CONTENT'][i].replace(item,'')\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(youtube['CONTENT'])):\n",
    "    for item in result:\n",
    "        youtube['CONTENT'][i]=youtube['CONTENT'][i].replace(item,'')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029d6eb5-ec20-47be-a5ba-b61b8e96e661",
   "metadata": {
    "id": "029d6eb5-ec20-47be-a5ba-b61b8e96e661"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "158a4e10-56e6-4d8b-8455-f5a2c119190d",
   "metadata": {
    "id": "158a4e10-56e6-4d8b-8455-f5a2c119190d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "  \n",
    "# importing edit distance  \n",
    "from nltk.metrics.distance  import edit_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af39dc9-ccc6-4e6a-8675-405d316984fa",
   "metadata": {},
   "source": [
    "#### در این کد زیر کلمات از دیکشنری گرفته می شوند."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "91ac98e1-d5d2-45f9-b976-685406b1f0f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91ac98e1-d5d2-45f9-b976-685406b1f0f4",
    "outputId": "74963773-9217-4efa-ae55-8fca6cf9f52e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "correct_words = words.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "499a31ed-f5c3-4f09-863e-6605de614b3c",
   "metadata": {
    "id": "O1HzpoOS3OZw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8a27b84-2d11-4ad1-a02b-63140d610596",
   "metadata": {},
   "source": [
    "#### در بخش تصحیح خطا لازم است اعداد از رشته حذف شوند. این به این علت است که هنگام تصحیح خطا با مشکل مواجه میشویم و چنین کلمه ای اصلا وجود ندارد. ما نیاز به ترکیب حروف الفبا داریم نه حروف الفبا و اعداد"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "H41H7WOm3T7n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H41H7WOm3T7n",
    "outputId": "a2f58ce2-bfb5-42f3-8ddd-9820728f9dbf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-70-c8df677acb78>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  youtube['CONTENT'][i]=youtube['CONTENT'][i].replace(str(item),'')\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(youtube['CONTENT'])):\n",
    "    number=[0,1,2,3,4,5,6,7,8,9]\n",
    "    #a=youtube['CONTENT'][i].split()\n",
    "    for item in number:\n",
    "        youtube['CONTENT'][i]=youtube['CONTENT'][i].replace(str(item),'')\n",
    "    #print(youtube['CONTENT'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72795d31-f7fe-4dec-9df9-02619ccf4a72",
   "metadata": {},
   "source": [
    "#### در راستای تشخیص خطا کلماتی که زبان غیرانگلیسی بودند مزاحمت ایجاد میکردند. به همین دلیل در ادامه ما سعی بر حذف کلمات غیر انگلیسی کردیم. تابع زیر بررسی میکند که یک کلمه انگلیسی است یا خیر. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ZPQ24iojK0r6",
   "metadata": {
    "id": "ZPQ24iojK0r6"
   },
   "outputs": [],
   "source": [
    "def isEnglish(s):\n",
    "    return s.isascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "NxtWBskII4B1",
   "metadata": {
    "id": "NxtWBskII4B1"
   },
   "outputs": [],
   "source": [
    "## delete none english words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6141bbea-d4e1-4c6f-abe9-74b613a56223",
   "metadata": {},
   "source": [
    "#### تابع زیر تمام حروف غیر انگلیسی را از رشته حذف میکند."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "lJseD2FbMO4X",
   "metadata": {
    "id": "lJseD2FbMO4X"
   },
   "outputs": [],
   "source": [
    "ascii = set(string.printable)\n",
    "def remove_non_ascii(s):\n",
    "    return list(filter(lambda x: x in ascii, s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ec8c45-b5c9-48b0-be93-a706892aa6ff",
   "metadata": {},
   "source": [
    "#### تابع قبل رشته را به صورت لیستی از حروف تشکیل دهنده اش بازمیگرداند که لازم است آن لیست را به صورت یک رشته در اوریم ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2Qmc1YLrHpfY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Qmc1YLrHpfY",
    "outputId": "7c36e7c8-1e9d-4c26-f1c8-9a69448f6132"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-74-c5304b630464>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  youtube['CONTENT'][i]=c\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(youtube['CONTENT'])):\n",
    "\n",
    "    a=remove_non_ascii(youtube['CONTENT'][i])\n",
    "    c=''\n",
    "    for j in a:\n",
    "        c+=j\n",
    "    youtube['CONTENT'][i]=c\n",
    "    #print(youtube['CONTENT'][i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd8d88-600e-40ef-83e4-2fc6c58ba1a0",
   "metadata": {},
   "source": [
    "#### در بخش پیش پردازش داده ها حروف بزرگ را به کوچک تبدیل کردم. همچنین فضای خالی اضافی را از بین بردم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "qiNT6Uku38KQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qiNT6Uku38KQ",
    "outputId": "1e8a982b-2d97-4f75-94b8-ac15fbe77fce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-75-2f84e408f5fb>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  youtube['CONTENT'][i]=(youtube['CONTENT'][i]).lower()\n",
      "<ipython-input-75-2f84e408f5fb>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  youtube['CONTENT'][i] = youtube['CONTENT'][i].strip()\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(youtube['CONTENT'])):\n",
    "    #print(youtube['CONTENT'][i])\n",
    "    ## turn to lower case\n",
    "    comment=youtube['CONTENT'][i]\n",
    "    youtube['CONTENT'][i]=(youtube['CONTENT'][i]).lower()\n",
    "    ## delete whitespace\n",
    "    youtube['CONTENT'][i] = youtube['CONTENT'][i].strip()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b01e96-6d9a-42f7-b3f6-6f7e5977866a",
   "metadata": {},
   "source": [
    "#### عبارتی که در قطعه کد زیر می بینید، در بخش تصحیح خطا ایجاد مزاحمت میکرد. لذا جملاتی که عبارت زیر را داشتند حذف شدند."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81862f1-daeb-4cd2-9d17-6986efd5a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(youtube['CONTENT'])):\n",
    "    #print(youtube['CONTENT'][i])\n",
    "    youtube['CONTENT'][i]=youtube['CONTENT'][i].replace('\\ufeff','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bd9807-9c63-49ef-8370-aee16b458e7f",
   "metadata": {},
   "source": [
    "## correct word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d242a30-458e-48f3-939b-306158559284",
   "metadata": {},
   "source": [
    "#### در بخش زیر ابتدا رشته را به صورت لیستی از کلمات در می اوریم.سپس بر روی هر کلمه عملیات تصحیح را اعمال میکنیم. تابع فاصله کلمه تا کلمات دیکشنری را بررسی میکند. بدین ترتیب کلمه ای که کمترین فاصله را دارد را به عنوان کلمه اصلی معرفی میکند. در صورتی که کلمه خاص باشد و فاصله بسیار زیادی تا دیگر کلمات داشته باشد، آن کلمه را خودش را در نظر میگیریم."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd27358-5250-4019-8b6e-ae845274db2b",
   "metadata": {},
   "source": [
    "#### نتیجه به صورت لیستی از کلمات است که مجددا آن را به شکل یک رشته کامل در می اوریم و نتیجه با تغییرات را ذخیره میکنیم."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c7be4c-9232-4b0a-a860-1b2f8c67e169",
   "metadata": {},
   "source": [
    "#### اعدادی که در خروجی این بخش میبینید، به علت ارورهای متوالی است که تا دقیقه نود داشتم. لذا برای دانستن اینکه کجا خطا دارد، ایندکس را چاپ کردم که در نهایت به علت کمبود وقت بدون این پرینت نتوانستم اجرا بگیرم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d7c8a8e7-d648-43a1-8b05-cdf62ce3fbdd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7c8a8e7-d648-43a1-8b05-cdf62ce3fbdd",
    "outputId": "72aaf03d-4d83-42a4-c34b-47ad84c2afe2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-1a6eb1bbf652>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  youtube['CONTENT'][i]=youtube['CONTENT'][i].replace('\\ufeff','')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-1a6eb1bbf652>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  youtube['CONTENT'][i]=c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "for i in range (len(youtube['CONTENT'])):\n",
    "    temp=word_tokenize(youtube['CONTENT'][i])\n",
    "    print(i)\n",
    "    new_sentence=[]\n",
    "    for word in temp:\n",
    "        if word not in result:\n",
    "            #print(word)\n",
    "            temp2 = [(edit_distance(word, w),w) for w in correct_words if w[0]==word[0]]\n",
    "            temp3=sorted(temp2, key = lambda val:val[0])\n",
    "            #print(temp3[0][1])\n",
    "            word=temp3[0][1]\n",
    "            new_sentence.append(word)\n",
    "\n",
    "    c=''\n",
    "    for k in new_sentence:\n",
    "        c+=k\n",
    "        c+=' '\n",
    "    youtube['CONTENT'][i]=c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2aa9ea",
   "metadata": {
    "id": "6a2aa9ea"
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5371cf4a-1482-4f16-9b93-1bad90dc0901",
   "metadata": {
    "id": "5371cf4a-1482-4f16-9b93-1bad90dc0901"
   },
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1bd44892",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1bd44892",
    "outputId": "28775995-cd78-4787-fa8d-f53f52e55e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'i': 129, 'the': 119, 'to': 115, 'and': 95, 'this': 90, 'my': 84, 'you': 64, 'view': 62, 'a': 60, 'check': 59, ...})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "vocabulary = []\n",
    "  \n",
    "for comment in youtube['CONTENT']:\n",
    "    \n",
    "    words = nltk.tokenize.word_tokenize(comment)\n",
    "    for word in words:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "vocabulary = nltk.FreqDist(vocabulary)\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "794a53ae-ef9c-4183-8bca-f0288d488b52",
   "metadata": {
    "id": "794a53ae-ef9c-4183-8bca-f0288d488b52"
   },
   "outputs": [],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "19404a17",
   "metadata": {
    "id": "19404a17"
   },
   "outputs": [],
   "source": [
    "# Keep 700 most common words as features\n",
    "# Note: Do not change this number\n",
    "word_features = [x[0] for x in vocabulary.most_common(700)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d90dd30b",
   "metadata": {
    "id": "d90dd30b"
   },
   "outputs": [],
   "source": [
    "# By doing this we'll consider every comment as a vector with 700 elements\n",
    "# So each elements says that it does contain the feature word or not\n",
    "data = []\n",
    "for comment in youtube['CONTENT']:\n",
    "    vector = {}\n",
    "    words = nltk.tokenize.word_tokenize(comment)\n",
    "    for word in word_features:\n",
    "        vector[word] = True if word in words else False\n",
    "        \n",
    "    data.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "60a6b855",
   "metadata": {
    "id": "60a6b855"
   },
   "outputs": [],
   "source": [
    "dataset = list(zip(data, youtube['CLASS']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbdb853",
   "metadata": {
    "id": "fcbdb853"
   },
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9e7025",
   "metadata": {
    "id": "2b9e7025"
   },
   "source": [
    "Note: Check the accuracy value of this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b4785137",
   "metadata": {
    "id": "b4785137"
   },
   "outputs": [],
   "source": [
    "XY_train, XY_test = train_test_split(dataset, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "347a3306",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "347a3306",
    "outputId": "2e464ca3-548e-41d5-8af1-ce6e6fb6e65d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model Accuracy: 0.8977272727272727\n"
     ]
    }
   ],
   "source": [
    "nltk_model = SklearnClassifier(KNeighborsClassifier())\n",
    "nltk_model.train(XY_train)\n",
    "accuracy = nltk.classify.accuracy(nltk_model, XY_test)\n",
    "print(\"model Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260f1036-f0d2-4ae9-94a0-fcdad0830b5e",
   "metadata": {},
   "source": [
    "#### همانطور که میبینید نتیجه عملیات پیش پردازشی که داشتیم به این دقت رسیده است. تمامی اعمال پیش پردازش لازم هستند و برخی از انها اگر اعمال نمیشد برنامه خطا میداد."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420c166a",
   "metadata": {
    "id": "420c166a"
   },
   "source": [
    "### Did you know that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada9ae4f",
   "metadata": {
    "id": "ada9ae4f"
   },
   "source": [
    "In this example we've constructed our vectors as dictionaries<br>\n",
    "because it's the required format of SklearnClassifier from nltk package<br>\n",
    "but we could consider each sentence (or in our case youtube comment) as<br>\n",
    "a simple 0, 1 array, where each element of this array represents the presence<br>\n",
    "of the corresponding feature word.<br>\n",
    "By doing so, we could use the official scikit package and pass our vectors to <br>\n",
    "the its 'fit' method<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2c09f048",
   "metadata": {
    "id": "2c09f048"
   },
   "outputs": [],
   "source": [
    "# data = []\n",
    "# for comment in youtube['CONTENT']:\n",
    "#     vector = []\n",
    "#     words = nltk.tokenize.word_tokenize(comment)\n",
    "#     for word in word_features:\n",
    "#         vector.append(True if word in words else False)\n",
    "        \n",
    "#     data.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9f6f1ff2",
   "metadata": {
    "id": "9f6f1ff2"
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(data, youtube['CLASS'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cbe58bdc",
   "metadata": {
    "id": "cbe58bdc"
   },
   "outputs": [],
   "source": [
    "# classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "# classifier.fit(X_train, y_train)\n",
    "# predicted = classifier.predict(X_test)\n",
    "\n",
    "# accuracy_score(y_test, predicted)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
